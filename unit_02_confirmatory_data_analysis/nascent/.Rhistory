#     kappa[j] = doKappaIntegral(z[j], Sigma[j,j], xi, w, tc,
#                           integral.transform, integral.numerical
#                           );
#     }
#
#   pi_m = mean(1-kappa);  # sum/m is the mean ...  EQN #8
#   pi_0 = 1 - pi_m;
#
#   pi_0;
tc = sqrt(2 * 1/2 * log(m) / max(varvec) );
info = buildChenConstrainedSupport("bump",
cparams = list("c"=1),
xdomain = c(-1.25, 1.25)
);
plotChenIntegralSetup(info);
fparams = list("tc" = tc, "sigma.jj" = sqrt(varvec[100]), "z.j" = z[100]);
FUN = " yi* exp( (tc^2 * xi^2 * sigma.jj)/2) * cos( tc * xi * z.j)";
computeNumericalIntegration(info, FUN=FUN, fparams=fparams);
plotChenIntegralSetup(info);
fparams = list("tc" = tc, "sigma.jj" = sqrt(varvec[2500]), "z.j" = z[2500]);
FUN = " yi* exp( (tc^2 * xi^2 * sigma.jj)/2) * cos( tc * xi * z.j)";
computeNumericalIntegration(info, FUN=FUN, fparams=fparams);
plotChenIntegralSetup(info);
fparams = list("tc" = tc, "sigma.jj" = sqrt(varvec[8500]), "z.j" = z[8500]);
FUN = " yi* exp( (tc^2 * xi^2 * sigma.jj)/2) * cos( tc * xi * z.j)";
computeNumericalIntegration(info, FUN=FUN, fparams=fparams);
tc = sqrt(2 * 1/2 * log(m) / max(varvec) );
info = buildChenConstrainedSupport("bump",
cparams = list("c"=1),
xdomain = c(-1.25, 1.25)
);
plotChenIntegralSetup(info);
fparams = list("tc" = tc, "varvec" = varvec, "z" = z);
FUN = "yi*mean(exp((tc*xi)^2*varvec/2)*cos(tc*xi*z))";
computeNumericalIntegration(info, FUN=FUN, fparams=fparams);
plotChenIntegralSetup(info);
fparams = list("tc" = tc, "sigma.jj" = sqrt(varvec[100]), "z.j" = z[100]);
FUN = " yi* exp( (tc^2 * xi^2 * sigma.jj)/2) * cos( tc * xi * z.j)";
computeNumericalIntegration(info, FUN=FUN, fparams=fparams);
plotChenIntegralSetup(info);
fparams = list("tc" = tc, "sigma.jj" = sqrt(varvec[2500]), "z.j" = z[2500]);
FUN = " yi* exp( (tc^2 * xi^2 * sigma.jj)/2) * cos( tc * xi * z.j)";
computeNumericalIntegration(info, FUN=FUN, fparams=fparams);
plotChenIntegralSetup(info);
fparams = list("tc" = tc, "sigma.jj" = sqrt(varvec[8500]), "z.j" = z[8500]);
FUN = " yi* exp( (tc^2 * xi^2 * sigma.jj)/2) * cos( tc * xi * z.j)";
computeNumericalIntegration(info, FUN=FUN, fparams=fparams);
library(pracma);
F.s= function(z.j,sigma.jj,s,ftype="exponential",cparams=list("b" = 3, "h" = 1), xdomain = c(-0.25, 1.25)){
## N=2*exp( 0.5*(s*z.j - (sigma.jj^2)*(s^2)) )
## D=erfz( (2^(-0.5))* ( s*sigma.jj - (z.j/sigma.jj)))
#change to
N= 2*exp( 0.5*(- (sigma.jj^2)*(s^2)) )
D=1-erfz( (2^(-0.5))* ( s*sigma.jj ))
#and drop z.j parameter
fparams = list(s=s);
info=buildAdeboConstrainedSupport( ftype=ftype,cparams=cparams,xdomain=xdomain)
plotAdeboIntegralSetup(info);
int.info=
computeNumericalIntegration(info,FUN="yi/(s+xi)",fparams=fparams);
(N/D)*int.info$total
}
F.s(0,1,1)
library(elliptic);
kappa.j=function(z.j,sigma.jj,s,tc=3,ftype="exponential",cparams=list("b" = 3, "h" = 1), xdomain = c(-0.25, 1.25)){
g=Re(s)
C=(2/pi)*exp(g*z)
L.inv=function(x, z.j=z.j,sigma.jj=sigma.jj)
{
cos(tc*z*x)* F.s(z,sigma.jj,g+1i*tc*x)
#should be adjusted to:
#cos(tc*z.j*x)*(F.s(sigma.jj, g +1i*tc*x))
}
#I believe each z should become a z.j above
# int.info = myintegrate(L.inv,0,1);
# at each eps ... keep the real part ...
C * int.info;
}
info = buildAdeboConstrainedSupport("exponential",
cparams = list("b" = 3, "h" = 1),
xdomain = c(-0.25, 1.25)
);
plotAdeboIntegralSetup(info);
fparams = list(s=1);
computeNumericalIntegration(info,FUN="yi/(s+xi)",fparams=fparams);
info = buildAdeboConstrainedSupport("exponential",
cparams = list("b" = 3, "h" = 1),
xdomain = c(-0.25, 1.25)
);
tcs=seq(0,50,by=5);
for(tc in tcs)
{
plotAdeboIntegralSetup(info);
fparams = list("tc" = tc);
computeNumericalIntegration(info,FUN="yi*exp(-1*tc*xi)",fparams=fparams);
Sys.sleep(1);
}
info = buildAdeboConstrainedSupport("quadratic",
cparams = list("h" = 0),
xdomain = c(-0.25, 1.25)
);
tcs=seq(0,50,by=5);
for(tc in tcs)
{
plotAdeboIntegralSetup(info);
fparams = list("tc" = tc);
computeNumericalIntegration(info,FUN="yi*exp(-1*tc*xi)",fparams=fparams);
Sys.sleep(1);
}
info = buildAdeboConstrainedSupport("wavelet",
cparams = list("a" = 0, "b"=0,"n"=2),
xdomain = c(-0.25, 1.25)
);
tcs=seq(0,50,by=5);
for(tc in tcs)
{
plotAdeboIntegralSetup(info);
fparams = list("tc" = tc);
computeNumericalIntegration(info,FUN="yi*exp(-1*tc*xi)",fparams=fparams);
Sys.sleep(1);
}
info = buildAdeboConstrainedSupport("exponential",
cparams = list("b" = 3, "h" = 1),
xdomain = c(-0.25, 1.25)
);
T=50
tcs=0:T
s=1
total.area=0
for(tc in tcs){
plotAdeboIntegralSetup(info);
fparams = list("tc" = tc);
res=computeNumericalIntegration(info,FUN="exp(-1*tc*xi)",fparams=fparams);
C=res$total
}
C.t=function(tc){
info = buildAdeboConstrainedSupport("quadratic",
cparams = list("h" = 0),
xdomain = c(-0.25, 1.25)
);
plotAdeboIntegralSetup(info);
fparams = list("tc" = tc);
res=computeNumericalIntegration(info,FUN="yi*exp(-1*tc*xi)",fparams=fparams);
res$total
}
# #These were nonlinear growth curves
# myModel.fcn3 = function (X,params) { params$b/(1+exp(-params$d*(X-params$t)))}
# 	myModel.nlm3 = Y ~ b/(1+exp(-d*(X-t)));		## 3 parameters:  ceiling, growth, shift
# 	#this is exponential decay
#
# myModel.fcn3 = function (X,params) { params$a*exp(params$b*(X-params$h)) + params$k}
# myModel.nlm3 = Y ~ a*exp(b*(X-h)) + k;
# x=1:50
# y=res
# df=as.data.frame(cbind(y,x));
# colnames(df)=c("Y","X")
# nls(myModel.nlm3, df)
# 	myModel.fcn2 = function (X,params) {
# params$a*X^(-1*params$b)}
# 		myModel.nlm2 = Y ~ a*X^(-1*b);
#
#
# x=1:50
# y=res
# df=as.data.frame(cbind(y,x))
# colnames(df)=c("Y","X")
# nls.fit=nls(myModel.nlm2, df,start=list(a=1, b=2))
# 	> summary(nls.fit)$coefficients[,1]
#         a         b
# 0.7784899 0.7340640
library(elliptic)
#myintegrate(function(t){C.t(t)*exp(-1*s*t)}, 0,Inf);
res=c()
for(i in 1:500){
a=C.t(i)
res=c(res,a)
}
res2=c()
js=seq(0,1,by=0.01)
for(j in js){
a=C.t(j)
res2=c(res2,a)
}
res3=c()
js=seq(0,0.1,by=0.005)
for(j in js){
a=C.t(j)
res3=c(res3,a)
}
res4=c(res3,res2,res);plot(unique(res4));  C.t(0);C.t(1)
##################
X = 1:500;
Y = res;
df=as.data.frame(cbind(X,Y))
colnames(df)=c("X","Y")
myModel.fcn4 = function (X,params) { params$a*exp(params$b*(X-params$h))+params$k }
myModel.nlm4 = Y ~ a*exp(b*(X-h))+k
myModel.fcn2 = function (X,params) { params$a*exp(params$b*X) }
myModel.nlm2 = Y ~ a*exp(b*X)
model.0 <- lm(log(Y) ~ X, data=df);
a = as.numeric(exp(coef(model.0)[1]));
b = as.numeric(coef(model.0)[2]);
params = list(a=0.27, b=-0.05, h=0, k=0);
myModel.fcn3 = function (X,params) { params$a*exp(params$b*X)+params$k }
myModel.nlm3 = Y ~ a*exp(b*X)+k
# params = list(a=0.761663, b=-0.221062, k=0.049338);
params = list(a=0.679310 , b=-0.141768);
Y2 =  myModel.fcn2(X, params);
plot(X,Y , col="red", ylim=c(0,1));
par(new=TRUE);
plot(X,Y2 , col="blue", ylim=c(0,1));
# https://stats.stackexchange.com/questions/160552/why-is-nls-giving-me-singular-gradient-matrix-at-initial-parameter-estimates
# https://www.r-bloggers.com/2012/07/a-better-nls/
nls.fit = nls(myModel.nlm2, df, start=params,
control = nls.control(warnOnly = F)
);
summary(nls.fit);
a.0.1 = (C.t(0) + C.t(1)) / 2;
a.1.Inf = integrate( myModel.fcn2, lower=1, upper=Inf, params)$value;
area = a.0.1 + a.1.Inf;
sum(res[1:20]);
integrate( myModel.fcn2, lower=1, upper=Inf, params)
integrate( myModel.fcn2, lower=1,  upper=10^10, params)# ???
integrate( myModel.fcn2, lower=1,  upper=10^100, params)# ???
# library(minpack.lm)
# nls.fit2 = nlsLM(myModel.nlm4, df,start=params)
C.t=function(tc){
info = buildAdeboConstrainedSupport("quadratic",
cparams = list("h" = 0),
xdomain = c(-0.25, 1.25)
);
plotAdeboIntegralSetup(info);
fparams = list("tc" = tc);
res=computeNumericalIntegration(info,FUN="yi*exp(-1*tc*xi)",fparams=fparams);
res$total
}
# a.0.1 = (C.t(0) + C.t(1)) / 2;
myInf = 20;
dxi = seq(0,myInf,by=.01);
total = length(dxi);
s = 1 + 2i;  # erfz(s)
area = 0;
epsA = numeric(total);
C.tA = numeric(total);
Cx = Cxn = NULL;
j = 1;
for(i in 1:total)
{
# we look ahead, last one
# we will do current and next
x = dxi[i];
xn = dxi[i+1];
if(j == 1)
{
Cx = C.t(x);
} else { Cx = Cxn; } # from previous iteration
Cxn = C.t(xn);
y = Cx * exp(-s*x);
yn = Cxn * exp(-s*xn);
eps = abs(xn - x) * (y + yn) / 2;
print(paste0(i,"/",total," ----> ",eps));
epsA[j] = eps;
C.tA[j] = Cx;
j = 1+j;
area = eps + area;
}
install.packages("RcppEigen", type="source");
install.packages("RcppArmadillo", type="source");
library(Rcpp)
A <- matrix(rnorm(10000), 100, 100)
B <- matrix(rnorm(10000), 100, 100)
library(microbenchmark)
sourceCpp("multiply.cpp")
include.me = paste0(path.github, "humanVerseWSU/R/functions-file.R");
source_url( include.me );
this.path = getDirectoryOfThisFile();  # will work in RStudio
library(devtools);
library(humanVerseWSU);
path.github = "https://raw.githubusercontent.com/MonteShaffer/humanVerseWSU/master/";
include.me = paste0(path.github, "misc/functions-nlp.R");
source_url( include.me );
include.me = paste0(path.github, "misc/functions-nlp-str.R");
source_url( include.me );
include.me = paste0(path.github, "misc/functions-nlp-stack.R");
source_url( include.me );
include.me = paste0(path.github, "misc/functions-nlp-pos.R");
source_url( include.me );
include.me = paste0(path.github, "humanVerseWSU/R/functions-encryption.R");
source_url( include.me );
path.to.nascent = "C:/Users/Alexander Nevsky/Dropbox/WSU-419/Fall 2020/__student_access__/unit_02_confirmatory_data_analysis/nascent/";
folder.nlp = "nlp/";
path.to.nlp = paste0(path.to.nascent, folder.nlp);
###### UPDATES TO dataframe subset function ######
# inflation adjustments for NA ... and improvements on subsetting
include.me = paste0(path.github, "humanVerseWSU/R/functions-dataframe.R");
source_url( include.me );
include.me = paste0(path.github, "humanVerseWSU/R/functions-inflation.R");
source_url( include.me );
include.me = paste0(path.github, "humanVerseWSU/R/functions-file.R");
source_url( include.me );
this.path = getDirectoryOfThisFile();  # will work in RStudio
library(Rcpp)
A <- matrix(rnorm(10000), 100, 100)
B <- matrix(rnorm(10000), 100, 100)
library(microbenchmark)
sourceCpp("multiply.cpp")
microbenchmark(A%*%B, armaMatMult(A, B), eigenMatMult(A, B), eigenMapMatMult(A, B))
getwd()
include.me = paste0(path.github, "humanVerseWSU/R/functions-file.R");
source_url( include.me );
this.path = getDirectoryOfThisFile();  # will work in RStudio
setwd(this.path);
include.me = paste0(path.github, "humanVerseWSU/R/functions-file.R");
source_url( include.me );
this.path = getDirectoryOfThisFile();  # will work in RStudio
setwd(this.path);
library(Rcpp)
A <- matrix(rnorm(10000), 100, 100)
B <- matrix(rnorm(10000), 100, 100)
library(microbenchmark)
sourceCpp("multiply.cpp")
microbenchmark(A%*%B, armaMatMult(A, B), eigenMatMult(A, B), eigenMapMatMult(A, B))
include.me = paste0(path.github, "humanVerseWSU/R/functions-file.R");
source_url( include.me );
this.path = getDirectoryOfThisFile();  # will work in RStudio
setwd(this.path);
library(Rcpp)
A <- matrix(rnorm(10000), 100, 100)
B <- matrix(rnorm(10000), 100, 100)
library(microbenchmark)
sourceCpp("multiply.cpp")
microbenchmark(A%*%B, armaMatMult(A, B), eigenMatMult(A, B), eigenMapMatMult(A, B))
include.me = paste0(path.github, "humanVerseWSU/R/functions-file.R");
source_url( include.me );
this.path = getDirectoryOfThisFile();  # will work in RStudio
setwd(this.path);
library(Rcpp)
A <- matrix(rnorm(10000), 100, 100)
B <- matrix(rnorm(10000), 100, 100)
library(microbenchmark)
sourceCpp("multiply.cpp")
microbenchmark(eigenMatTrans(A),A%*%B, armaMatMult(A, B), eigenMatMult(A, B), eigenMapMatMult(A, B))
timer.start = as.numeric(Sys.time());
# AA = AM %*% t(AM);
AM.t = eigenMatTrans(AM);
myV = c(0,0,0,0,0,0,0,0,0,0,
0,0,0,0,0,0,0,0,0,0,
0,0,0,0,0,0,0,0,0,0,
0,1,1,0,0,0,0,0,0,0,
1,1,0,0,0,0,0,0,0,0,
0,0,0,0,0,0,0,0,0,0,
1,1,0,0,1,1,0,0,0,0,
1,0,0,1,0,1,0,0,0,0,
0,0,1,0,0,0,0,0,0,0,
0,0,0,0,0,1,0,1,0,0);
myA = matrix(myV, nrow=10, byrow=TRUE);
rownames(myA) = colnames(myA) = paste0("P.",1:10);
myA;
# row sort
rs = rowSums(myA);
rs.s = sort(rs);
rs.idx = as.numeric( gsub("P.","",names(rs.s)) );
myA.s = myA[rs.idx,];
myA.s;
# col sort
cs = colSums(myA.s);
cs.s = sort(cs);
cs.idx = as.numeric( gsub("P.","",names(cs.s)) );
myA.ss = myA.s[,cs.idx];
myA.ss;
order = c(1,2,3,6,4,5,8,7,9,10);
myA.f = myA[order,order];
myA.f;
df = subsetDataFrame(imdb.data$movies$popular50, "year", ">=", 1980);
library(imdb);
packageVersion("imdb");  # ‘0.1.1’
imdb::loadDataIMDB();
names(imdb.data);
df = subsetDataFrame(imdb.data$movies$popular50, "year", ">=", 1980);
df = subsetDataFrame(df, "year", "<", 2020);
ttids = df$ttid;
dim(df);
df.cast = merge(df, imdb.data$movies.df$cast, by="ttid");
dim(df.cast);
length(unique(df.cast$ttid));
length(unique(df.cast$nmid));
network = df.cast;
n.ttid = length(unique(network$ttid));
n.nmid = length(unique(network$nmid));
my.ttids = sort( unique(network$ttid) );
my.nmids = sort( unique(network$nmid) );
AM = matrix(0, nrow=n.nmid, ncol=n.ttid);
rownames(AM) = my.nmids;
colnames(AM) = my.ttids;
dim(AM);
AM[1:10,1:5];
nrow = nrow(network);
nrow;
for(i in 1:nrow)
{
if(i %% 25000 == 1) { print(i); flush.console();}
row = network[i,];
ttid = row$ttid;
nmid = row$nmid;
r = which(my.nmids == nmid);
c = which(my.ttids == ttid);
AM[r,c] = 1;
}
sum(AM);
timer.start = as.numeric(Sys.time());
# AA = AM %*% t(AM);
AM.t = eigenMatTrans(AM);
AA = eigenMatMult(AM, AM.t);
timer.end = as.numeric(Sys.time());
elapsed = round(timer.end - timer.start,2);
print(paste0("Time: ", elapsed, " secs"));  # "Time: 392.57 secs"
dim(AA);
timer.start = as.numeric(Sys.time());
# MM = t(AM) %*% (AM);
MM = eigenMatMult(AM.t, AM);
timer.end = as.numeric(Sys.time());
elapsed = round(timer.end - timer.start,2);
print(paste0("Time: ", elapsed, " secs")); # "Time: 45.83 secs"
dim(MM);
392.57/14.8
45.83 / 2.17
which(rownames(AM)==nmid);
nmid1 = "nm0000243";
idx = which(rownames(AM)==nmid);
AM.r = AM[idx,];
idx0 = which(AM.r == 0);
AM.rs = AM.r[-c(idx0)];
AM.rs;
nmid1 = "nm0000243";
idx = which(rownames(AA)==nmid);
AA.r = AA[idx,];
idx0 = which(AA.r == 0);
AA.rs = AA.r[-c(idx0)];
AA.rs;
rownames(MM) = colnames(MM) = my.ttids;
rownames(AA) = colnames(AA) = my.nmids;
nmid1 = "nm0000243";
idx = which(rownames(AA)==nmid);
idx
AA.r = AA[idx,];
which(AA.r == 0);
idx0 = which(AA.r == 0);
AA.rs = AA.r[-c(idx0)];
AA.rs;
?image
df.will = subsetDataFrame(imdb.data$movies.df$cast, "nmid" , "==", "nm0000226");
View(df.will)
df.will = subsetDataFrame(network, "nmid" , "==", "nm0000226");
View(df.will)
df.denzel = subsetDataFrame(network, "nmid" , "==", "nm0000243");
View(df.denzel)
nmid1 = "nm0000243";
idx = which(rownames(AA)==nmid);
AA.r = AA[idx,];
idx0 = which(AA.r == 0);
AA.rs = AA.r[-c(idx0)];
AA.rs;
nmid1 = "nm0000226";
idx = which(rownames(AA)==nmid);
AA.r = AA[idx,];
idx0 = which(AA.r == 0);
AA.rs = AA.r[-c(idx0)];
AA.rs;
nmid1 = "nm0000226";
idx = which(rownames(AA)==nmid1);
AA.r = AA[idx,];
idx0 = which(AA.r == 0);
AA.rs = AA.r[-c(idx0)];
AA.rs;
sort(AA.rs)
nmid = "nm0000226";
idx = which(rownames(AA)==nmid);
AA.r = AA[idx,];
idx0 = which(AA.r == 0);
AA.rs = sort(AA.r[-c(idx0,idx)], decreasing=TRUE); # remove zeroes and self
length(AA.rs);  # number of unique actors
sum(AA.rs);  # total ties.  one actor may be higher than another
head(AA.rs);
nmid = "nm0000243";
idx = which(rownames(AA)==nmid);
AA.r = AA[idx,];
idx0 = which(AA.r == 0);
AA.rs = sort(AA.r[-c(idx0,idx)], decreasing=TRUE); # remove zeroes and self
length(AA.rs);  # number of unique actors
sum(AA.rs);  # total ties.  one actor may be higher than another
head(AA.rs);
nmid = "nm0000226";
idx = which(rownames(AA)==nmid);
AA.r = AA[idx,];
idx0 = which(AA.r == 0);
AA.rs = sort(AA.r[-c(idx0,idx)], decreasing=TRUE); # remove zeroes and self
length(AA.rs);  # number of unique actors
sum(AA.rs);  # total ties.  one actor may be higher than another
head(AA.rs,10);
nmid = "nm0000243";
idx = which(rownames(AA)==nmid);
AA.r = AA[idx,];
idx0 = which(AA.r == 0);
AA.rs = sort(AA.r[-c(idx0,idx)], decreasing=TRUE); # remove zeroes and self
length(AA.rs);  # number of unique actors
sum(AA.rs);  # total ties.  one actor may be higher than another
head(AA.rs,10);
AA.1 = eigenMatMult(AA, AA);
AA.2 = eigenMatMult(AA.1, AA);
AA.3 = eigenMatMult(AA.2, AA);
AA.4 = eigenMatMult(AA.3, AA);
AA.5 = eigenMatMult(AA.4, AA);
